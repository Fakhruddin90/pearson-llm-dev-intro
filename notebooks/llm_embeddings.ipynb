{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed0bd5aa-e05f-48da-9ddc-c13235868a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Function to calculate cosine similarity\n",
    "def get_cosine_similarity(embedding1, embedding2):\n",
    "    # Calculate cosine similarity (note: scipy's cosine function actually computes the distance, so we subtract from 1)\n",
    "    cos_sim = 1 - cosine(embedding1, embedding2)\n",
    "    return cos_sim\n",
    "\n",
    "# Initialize the model\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# Example sentences\n",
    "sentences = [\"This is an example sentence\", \"This is also an example sentence.\"]\n",
    "\n",
    "# Generate embeddings\n",
    "embedding1, embedding2 = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203015b7-f09e-4778-96e3-e427cf8b8843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3096113e-38b6-4a95-84bd-966807b2612e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.8140871524810791\n"
     ]
    }
   ],
   "source": [
    "# Calculate similarity\n",
    "similarity = get_cosine_similarity(embedding1, embedding2)\n",
    "print(\"Cosine Similarity:\", similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24953c6d-5641-480e-8c1f-fd13d0387f51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b232f03-8dd1-4887-860d-82dd5cb2ba72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.42858538031578064\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"I like this\", \"I hate this\"]\n",
    "\n",
    "# Generate embeddings\n",
    "embedding1, embedding2 = model.encode(sentences)\n",
    "\n",
    "# Calculate similarity\n",
    "similarity = get_cosine_similarity(embedding1, embedding2)\n",
    "print(\"Cosine Similarity:\", similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe201926-ea91-4cf0-846c-6bdb9b639c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c37299a-89c7-4f60-90a5-10c4bb543803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "def get_word_embedding(sentence, word, model, tokenizer, model_type='bert'):\n",
    "    # Tokenize and encode the sentence\n",
    "    encoded_input = tokenizer(sentence, return_tensors='pt')\n",
    "    tokens = tokenizer.convert_ids_to_tokens(encoded_input['input_ids'][0])\n",
    "\n",
    "    # Find the index of the word (handling potential subword tokenization)\n",
    "    word_tokens = tokenizer.tokenize(word)\n",
    "    word_index = None\n",
    "    for i in range(len(tokens) - len(word_tokens) + 1):\n",
    "        if tokens[i:i + len(word_tokens)] == word_tokens:\n",
    "            word_index = i\n",
    "            break\n",
    "    if word_index is None:\n",
    "        raise ValueError(f\"Word '{word}' not found in the tokenized sentence.\")\n",
    "\n",
    "    # Get model output\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded_input)\n",
    "\n",
    "    # Extract the embedding for the specified word (for GPT models, take the last layer)\n",
    "    if model_type == 'bert':\n",
    "        word_embedding = output.last_hidden_state[0, word_index, :]\n",
    "    elif model_type == 'gpt':\n",
    "        word_embedding = output['last_hidden_state'][0, word_index, :]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type specified. Choose 'bert' or 'gpt'.\")\n",
    "    \n",
    "    return word_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03769993-e6ed-417c-833a-5a05f76c7493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained models and tokenizers\n",
    "\n",
    "# For BERT\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# For GPT-2\n",
    "gpt_tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "gpt_model = AutoModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5e1217-b14b-44d8-a499-2f8a4e472632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f161f8d-ed4a-44f2-bbbf-5ca28f279ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Initial Embedding for 'river': tensor([ 0.1578,  0.4036, -0.3913,  0.1713, -0.1797])\n",
      "GPT-2 Initial Embedding for 'river': tensor([0.0582, 0.0548, 0.2876, 0.0670, 0.1042])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "def get_initial_word_embedding(word, tokenizer, model, model_type='bert'):\n",
    "    # Tokenize and encode the word\n",
    "    encoded_input = tokenizer(word, return_tensors='pt')\n",
    "    tokens = tokenizer.convert_ids_to_tokens(encoded_input['input_ids'][0])\n",
    "\n",
    "    # Handling the case when a word is split into subwords\n",
    "    if len(tokens) > 3:  # Including special tokens [CLS], [SEP] for BERT or GPT-2\n",
    "        raise ValueError(\"The word was split into subwords. Please provide a single token.\")\n",
    "\n",
    "    # Extract the token index (excluding special tokens)\n",
    "    token_index = 1 if model_type == 'bert' else 0\n",
    "\n",
    "    # Get the embeddings\n",
    "    with torch.no_grad():\n",
    "        if model_type == 'bert':\n",
    "            embeddings = model.embeddings(encoded_input['input_ids'])[0, token_index, :]\n",
    "        elif model_type == 'gpt':\n",
    "            # For GPT-2, manually apply the embedding layer\n",
    "            input_ids = encoded_input['input_ids']\n",
    "            embeddings = model.wte(input_ids)[0, token_index, :]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid model type specified. Choose 'bert' or 'gpt'.\")\n",
    "\n",
    "    return embeddings\n",
    "    \n",
    "# Example word\n",
    "word = \"river\"\n",
    "\n",
    "# Get initial embedding for BERT\n",
    "bert_initial_embedding = get_initial_word_embedding(word, bert_tokenizer, bert_model, 'bert')\n",
    "print(\"BERT Initial Embedding for '{}':\".format(word), bert_initial_embedding[:5])\n",
    "\n",
    "# Get initial embedding for GPT-2\n",
    "gpt_initial_embedding = get_initial_word_embedding(word, gpt_tokenizer, gpt_model, 'gpt')\n",
    "print(\"GPT-2 Initial Embedding for '{}':\".format(word), gpt_initial_embedding[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a07c5af-87b6-41f2-b492-c6a6cc3b5274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "437895fb-7627-4c21-93d3-572f5d7485d4",
   "metadata": {},
   "source": [
    "# Starting with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4da4040c-c6ac-471e-8b56-94af7fdc165c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for 'bank': tensor([ 0.2764, -0.4860,  0.2104, -0.3106, -0.0630])\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I went to the river bank for a nice walk.\"\n",
    "word = \"bank\"\n",
    "\n",
    "# Get embedding for bank\n",
    "embedding = get_word_embedding(sentence, word, bert_model, bert_tokenizer)\n",
    "print(\"Embedding for '{}':\".format(word), embedding[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6707430-fba7-47f2-a769-1b7cb260a864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate similarity to initial lake/money embedding\n",
    "water_embedding = get_initial_word_embedding('water', bert_tokenizer, bert_model, 'bert')\n",
    "money_embedding = get_initial_word_embedding('money', bert_tokenizer, bert_model, 'bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70d59d97-54c5-4c76-8f1a-3f711ef2b61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity to water: 0.06027546897530556\n",
      "Cosine Similarity to money: 0.004379441495984793\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine Similarity to water:\", get_cosine_similarity(embedding, water_embedding))\n",
    "print(\"Cosine Similarity to money:\", get_cosine_similarity(embedding, money_embedding))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cff8d1e-4dd3-43be-b417-861583a7e6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for 'bank': tensor([ 0.7613, -0.3984, -0.1457, -0.1107,  1.2720])\n"
     ]
    }
   ],
   "source": [
    "# bank for cash\n",
    "sentence = \"I went to the bank to get some cash out of savings.\"\n",
    "word = \"bank\"\n",
    "\n",
    "# bank has a different embedding\n",
    "embedding = get_word_embedding(sentence, word, bert_model, bert_tokenizer)\n",
    "print(\"Embedding for '{}':\".format(word), embedding[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fcf9e5f-aa0c-4e77-81c5-b2d5c8551497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity to water: -0.0015438803238794208\n",
      "Cosine Similarity to money: 0.061874888837337494\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine Similarity to water:\", get_cosine_similarity(embedding, water_embedding))\n",
    "print(\"Cosine Similarity to money:\", get_cosine_similarity(embedding, money_embedding))\n",
    "\n",
    "# similarity went down compared to water and up for money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aa7c6a-bd5a-4683-9269-015824c68212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "252f4a89-bf6e-48e2-9d0e-c3edec338909",
   "metadata": {},
   "source": [
    "# Now with GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92a238f-72da-4bc2-9917-f3cc41c4be55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For gpt, position matters for embeddings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97117d33-6282-41ac-899a-b9d21ea46312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for ' bank': tensor([-0.1299, -0.3162, -1.0468,  0.1864,  0.2709])\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I went to the bank to get some cash\"\n",
    "word = \" bank\"  # gpt tokenizer prepends spaces\n",
    "\n",
    "# Get embedding\n",
    "embedding = get_word_embedding(sentence, word, gpt_model, gpt_tokenizer)\n",
    "print(\"Embedding for '{}':\".format(word), embedding[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "126b8c6d-f135-4f9c-bf68-d316fc3b61f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for ' bank': tensor([-0.1299, -0.3162, -1.0468,  0.1864,  0.2709])\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I went to the bank of the river\"\n",
    "word = \" bank\"\n",
    "\n",
    "embedding = get_word_embedding(sentence, word, gpt_model, gpt_tokenizer)\n",
    "print(\"Embedding for '{}':\".format(word), embedding[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c7a00e-ccb4-49a0-81d6-97cb9fbb522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same embedding for \" bank\" because all words are the same before \" bank\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae5c157-38c8-4d85-9ca6-8fd08017dc84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481fec3e-1579-4540-bebf-fde63587ed00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dcefb9-834c-43d3-ab57-6cec70289f71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
